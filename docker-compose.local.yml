version: '3.8'

services:
  bot:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: telegram-ollama-bot-local
    restart: unless-stopped
    environment:
      - BOT_TOKEN=${BOT_TOKEN}
      - DEFAULT_LANGUAGE=${DEFAULT_LANGUAGE:-en}
      - DEV=${DEV:-true}
      - DEFAULT_MODEL=${DEFAULT_MODEL:-llama3.2}
      # Use host's Ollama instance (host.docker.internal resolves to the host machine)
      - OLLAMA_HOST=host.docker.internal
      - OLLAMA_PORT=11434
      - PYTHONUNBUFFERED=1
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M
    network_mode: "bridge" 